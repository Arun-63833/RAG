{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12311483,"sourceType":"datasetVersion","datasetId":7760040}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n!pip install -q pydantic==2.5.3\n!pip install -q langchain-core==0.1.52\n!pip install -q langchain==0.1.17\n!pip install -q langchain-community==0.0.37\n!pip install -q langchain-nvidia-ai-endpoints==0.0.8\n!pip install -q pymupdf\n!pip install -q faiss-cpu\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:44:41.182493Z","iopub.execute_input":"2025-07-02T13:44:41.182821Z","iopub.status.idle":"2025-07-02T13:45:39.651544Z","shell.execute_reply.started":"2025-07-02T13:44:41.182785Z","shell.execute_reply":"2025-07-02T13:45:39.650183Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-core 0.3.50 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\nlangchain 0.3.22 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.5.3 which is incompatible.\nalbumentations 2.0.5 requires pydantic>=2.9.2, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nlangchain-text-splitters 0.3.7 requires langchain-core<1.0.0,>=0.3.45, but you have langchain-core 0.1.52 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nlangchain 0.3.22 requires langchain-core<1.0.0,>=0.3.49, but you have langchain-core 0.1.52 which is incompatible.\nlangchain 0.3.22 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.5.3 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h/kaggle/input/bookrag/Principles-of-Bloodstain-Patter-Analysis-1.pdf\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom langchain_community.document_loaders import PyMuPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings\nfrom langchain_community.vectorstores import FAISS\nfrom langchain.chains import create_retrieval_chain\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.schema import Document\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T14:31:22.501273Z","iopub.execute_input":"2025-07-02T14:31:22.501663Z","iopub.status.idle":"2025-07-02T14:31:22.507641Z","shell.execute_reply.started":"2025-07-02T14:31:22.501636Z","shell.execute_reply":"2025-07-02T14:31:22.506666Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"os.environ[\"NVIDIA_API_KEY\"] = \"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\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T13:45:41.302371Z","iopub.execute_input":"2025-07-02T13:45:41.302931Z","iopub.status.idle":"2025-07-02T13:45:41.307873Z","shell.execute_reply.started":"2025-07-02T13:45:41.302874Z","shell.execute_reply":"2025-07-02T13:45:41.307116Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"chat_llm = ChatNVIDIA(model=\"ai-gemma-2-9b-it\")\nembedder = NVIDIAEmbeddings(model=\"ai-embed-qa-4\")\n\npdf_path = \"/kaggle/input/bookrag/Principles-of-Bloodstain-Patter-Analysis-1.pdf\"\nloader = PyMuPDFLoader(pdf_path)\ndocs = loader.load()\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=1000,\n    chunk_overlap=100,\n    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \", \"\"]\n)\ndocs_split = text_splitter.split_documents(docs)\nprint(\"Split complete\")\n\ndocuments_to_embed = [\n    Document(\n        page_content=doc.page_content,\n        metadata={\n            \"source\": f\"page_{doc.metadata.get('page', i)}\",\n            \"page\": doc.metadata.get(\"page\", i)\n        }\n    )\n    for i, doc in enumerate(docs_split)\n]\nprint(\"Embedding documents prepared\")\n\nvectorstore = FAISS.from_documents(documents_to_embed, embedder)\nvectorstore.save_local(\"faiss_index\")\nprint(\"FAISS index created and saved successfully.\")\n\nretriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n\nprompt = ChatPromptTemplate.from_template(\n    \"Answer the question using only the context below. Be specific and concise.\\n\"\n    \"<context>\\n\"\n    \"{context}\\n\"\n    \"</context>\\n\"\n    \"Question: {input}\"\n)\n\nretrieval_chain = RetrievalQAWithSourcesChain.from_chain_type(\n    llm=chat_llm,\n    retriever=retriever,\n    chain_type=\"stuff\",  \n    return_source_documents=True\n)\n\nquestion = \"What are the categories and subcategories in BPA?\"\nresponse = retrieval_chain.invoke({\"question\": question})\n\nprint(\"Answer:\\n\", response[\"answer\"])\nprint(\"\\nSources:\")\nfor i, doc in enumerate(response[\"source_documents\"]):\n    print(f\"\\n--- Source {i+1} ---\")\n    print(\"Source:\", doc.metadata.get(\"source\", \"N/A\"))\n    print(\"Page:\", doc.metadata.get(\"page\", \"N/A\"))\n    print(doc.page_content[:500], \"...\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-02T14:31:27.540619Z","iopub.execute_input":"2025-07-02T14:31:27.540954Z","iopub.status.idle":"2025-07-02T14:31:50.804434Z","shell.execute_reply.started":"2025-07-02T14:31:27.540931Z","shell.execute_reply":"2025-07-02T14:31:50.803499Z"}},"outputs":[{"name":"stdout","text":"Split complete\nEmbedding documents prepared\nFAISS index created and saved successfully.\nAnswer:\n The primary bloodstain pattern categories are passive, spatter, and altered. \n\nEach of these categories has subcategories:\n\n* **Passive:** Gravity, Saturation/Pooling, Free Falling\n* **Spatter:** Impact, Projection\n* **Altered:**  Diluted, Clotted, Dried, Diffused, Sequenced, Insects, Voids, Contact, Flow, Secondary\n\n\n\nSources:\n\n--- Source 1 ---\nSource: page_40\nPage: 40\nto begin with the primary bloodstain pattern categories — namely, passive, spatter, and\naltered — and proceed to speciﬁc subcategories based on case-driven facts.\nFigure 1.5\nBloodstain pattern categories.\nBloodstain Pattern Categories\nBloodstains\nPassive\nSpatter\nAltered\nTransfer\nFlow\nSecondary\nMechanism\nDiluted\nImpact\nMechanism\nClotted\nLarge\nVolume\nDrop(s)\nProjection\nMechanism\nDiffused\nSequenced\nInsects\nVoids ...\n\n\n--- Source 2 ---\nSource: page_99\nPage: 99\nlevels your analysis may attain dependent on available facts. As you proceed further down\nFigure 4.9\nPrimary bloodstain categories.\nFigure 4.10\nPrimary bloodstain categories with subcategories.\nBloodstains\nPassive/ \nGravity\nSpatter\nAltered\nBloodstains\nPassive/ \nGravity\nSpatter\nAltered\nContact\nFlow\nSecondary \nMechanism\nDiluted\nImpact \nMechanism\nClotted\nSaturation/ \nPooling \nFree Falling \nVolume\nDrop(s)\nProjection \nMechanism\nDried\nDiffused\nSequenced\nInsects\nVoids ...\n\n\n--- Source 3 ---\nSource: page_39\nPage: 39\nIntroduction to Bloodstain Pattern Analysis\n9\nbloodstain pattern analysts and practitioners in related ﬁelds from North America and\nEurope convened to discuss and evaluate methods, techniques, protocols, quality assurance,\neducation, and research relating to BPA. The group meets biannually. Subcommittees were\nestablished in the following areas:\n• Education and Training. This subcommittee addresses educational standards for\nstudents and instructors as well as standards for continuing education. \n ...\n\n\n--- Source 4 ---\nSource: page_32\nPage: 32\n• Possible movement and direction of victim, assailant, or objects at the scene after\nbloodshed\n• Support or contradiction of statements given by accused and/or witnesses\n• Additional criteria for estimation of postmortem interval\n• Correlation with other laboratory and pathology ﬁndings relevant to the investigation\nThe goal of the reconstruction of the crime scene using BPA is to assist the overall\nforensic investigation with the ultimate questions that must be addressed, which include,\nbut ar ...\n\n\n--- Source 5 ---\nSource: page_40\nPage: 40\n10\nPrinciples of Bloodstain Pattern Analysis: Theory and Practice\nConclusion\nThe taxonomic approach to the classiﬁcation of bloodstains and patterns is not entirely\nnew. It has been discussed among bloodstain pattern analysts for a long time and has been\ndescribed to varying extents in several texts published within the past ten years. The\nhierarchy of bloodstain categories that are discussed in this text combines the geometric\ncharacterization of the bloodstains with the events that caused the  ...\n\n","output_type":"stream"}],"execution_count":28}]}